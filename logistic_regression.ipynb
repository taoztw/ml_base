{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "970a8e16-c44f-47d5-84c8-88918fd6a6e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4015b87e-4a14-44cd-a0e5-b53aae6d32aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 随机生成二分类样本数据。\n",
    "# 每一个类别5000样本\n",
    "num_observations = 5000\n",
    "x1 = np.random.multivariate_normal([0,0],[[1,.75],[.75, 1]],num_observations)\n",
    "x2 = np.random.multivariate_normal([1,4],[[1,.75],[.75, 1]],num_observations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bac8f183-57b4-4e76-89e1-83f6858a9e72",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.vstack((x1,x2)).astype(np.float32)\n",
    "y = np.hstack((np.zeros(num_observations),np.ones(num_observations)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "ec9130e5-f0e6-4e90-9174-316f4f8ae351",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000, 2)\n",
      "(10000, 2)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x1.shape)\n",
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56420a53-b029-4527-90a8-366e95a59c42",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sigmoid(x):\n",
    "    return 1/(1+np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "92109fd7-7f4e-42b1-9942-9fa260cb54ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_likelihood(X,y,w,b):\n",
    "    \"\"\"\n",
    "    计算负的log likelihood, cross-entropy loss\n",
    "    N: 样本数量  D: 特征维度\n",
    "    X: (N,D)\n",
    "    y: (N,)\n",
    "    w: (D,)\n",
    "    b: 标量\n",
    "    \"\"\"\n",
    "    # 获得正样本和负样本的索引\n",
    "    pos, neg = np.where(y==1), np.where(y==0)\n",
    "    \n",
    "    # -sum[ y_i*log(sigmoid(wx+b)) + (1-y_i)*log(1-sigmoid(wx+b))]\n",
    "    # 计算 y_i*log(sigmoid(wx+b)) \n",
    "    pos_num = np.sum(np.log(sigmoid(np.dot(X[pos],w)+b)))\n",
    "    # 计算 (1-y_i)*log(1-sigmoid(wx+b))\n",
    "    neg_sum = np.sum(np.log(1-sigmoid(np.dot(X[neg],w)+b)))\n",
    "    \n",
    "    return -(pos_num + neg_sum)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "546ffd87-6272-4e3a-8f88-03a7d46f68f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def logistic_regression_train(X, y, batch_size, num_steps, lr):\n",
    "    \"\"\"\n",
    "    train\n",
    "    \"\"\"\n",
    "    w,b = np.zeros(X.shape[1]), 0\n",
    "    for step in range(num_steps):\n",
    "        #生成数据索引\n",
    "        batch = np.random.choice(X.shape[0],batch_size) \n",
    "        # 训练数据\n",
    "        X_batch, y_batch = X[batch], y[batch]\n",
    "        \n",
    "        # 计算梯度，log likelihood的导数 (y_hat-y)*x\n",
    "        error = sigmoid(np.dot(X_batch, w)+b) - y_batch\n",
    "        grad_w = np.matmul(X_batch.T, error)\n",
    "        grad_b = np.sum(error)\n",
    "        \n",
    "        w = w - lr * grad_w\n",
    "        b = b - lr * grad_b\n",
    "        \n",
    "        # 查看log likelihood\n",
    "        if step % 10000 == 0:\n",
    "            print(\"log likelihodd: \",log_likelihood(X,y,w,b))\n",
    "    return w, b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18faf842-2fb4-4026-9a7b-ff611db1eadf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "log likelihodd:  6419.139226954701\n",
      "log likelihodd:  262.4370478618892\n",
      "log likelihodd:  219.00758264431036\n",
      "log likelihodd:  203.11520791664208\n",
      "log likelihodd:  194.8640961717476\n",
      "log likelihodd:  189.7494168443975\n",
      "log likelihodd:  186.39211382161773\n",
      "log likelihodd:  184.0840011426568\n",
      "log likelihodd:  182.3301176646583\n",
      "log likelihodd:  181.08497032781776\n",
      "log likelihodd:  180.2518607149372\n",
      "log likelihodd:  179.30466305390422\n",
      "log likelihodd:  178.8039889038197\n",
      "log likelihodd:  178.1869077287103\n",
      "log likelihodd:  177.8546069070652\n",
      "log likelihodd:  177.42234499592757\n",
      "log likelihodd:  177.19025721379504\n",
      "log likelihodd:  176.95960956424963\n",
      "log likelihodd:  176.8820871070047\n",
      "log likelihodd:  176.6243105216392\n",
      "log likelihodd:  176.4756631709221\n",
      "log likelihodd:  176.3617810523368\n",
      "log likelihodd:  176.27659723645303\n",
      "log likelihodd:  176.2072233853113\n",
      "log likelihodd:  176.22254066633758\n",
      "log likelihodd:  176.08732573597004\n",
      "log likelihodd:  176.01763638488274\n",
      "log likelihodd:  175.954387820399\n",
      "log likelihodd:  175.91677943971246\n",
      "log likelihodd:  175.87747722592525\n",
      "log likelihodd:  175.84669435664748\n",
      "log likelihodd:  175.8487443416814\n",
      "log likelihodd:  175.798498064299\n",
      "log likelihodd:  175.79780518298352\n",
      "log likelihodd:  175.78513233903527\n",
      "log likelihodd:  175.75297737079904\n",
      "log likelihodd:  175.72748075925253\n",
      "log likelihodd:  175.76098546924317\n",
      "log likelihodd:  175.70871056361665\n",
      "log likelihodd:  175.73306447811908\n",
      "log likelihodd:  175.68718065326314\n",
      "log likelihodd:  175.71022722540357\n",
      "log likelihodd:  175.71129517655436\n",
      "log likelihodd:  175.66594129158162\n",
      "log likelihodd:  175.74341942989525\n",
      "log likelihodd:  175.72155052557486\n",
      "log likelihodd:  175.67902551702412\n",
      "log likelihodd:  175.66967902299837\n",
      "log likelihodd:  175.65265182232923\n",
      "log likelihodd:  175.68329719698636\n"
     ]
    }
   ],
   "source": [
    "w, b = logistic_regression_train(X, y, batch_size=100, num_steps = 500000, lr = 5e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7bfcd7b2-8ddc-4985-af45-8f37d0b2550d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "455e013a-bf4d-4502-817c-8e3c15724e41",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1000000000000000.0)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(fit_intercept=True, C = 1e15) # C设置很大，不想加入正则\n",
    "clf.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0cedaf56-6927-4db1-94fa-43336b352260",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "self 结果  [-4.5741644   7.31394704] -12.259032729459491\n",
      "slearn 结果  [[-4.63907718  7.41733945]] [-12.39910964]\n"
     ]
    }
   ],
   "source": [
    "print(\"self 结果 \", w, b)\n",
    "print(\"slearn 结果 \", clf.coef_, clf.intercept_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
